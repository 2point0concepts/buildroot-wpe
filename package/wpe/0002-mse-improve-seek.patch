diff -urN a/Source/WebCore/html/HTMLMediaElement.cpp b/Source/WebCore/html/HTMLMediaElement.cpp
--- a/Source/WebCore/html/HTMLMediaElement.cpp	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/html/HTMLMediaElement.cpp	2015-12-22 21:58:27.655842760 +0100
@@ -3429,7 +3429,7 @@
 #endif
 
 #if ENABLE(MEDIA_SOURCE)
-    if (m_mediaSource)
+    if (m_mediaSource && !m_player->seeking())
         m_mediaSource->monitorSourceBuffers();
 #endif
 }
diff -urN a/Source/WebCore/Modules/mediasource/MediaSource.cpp b/Source/WebCore/Modules/mediasource/MediaSource.cpp
--- a/Source/WebCore/Modules/mediasource/MediaSource.cpp	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/Modules/mediasource/MediaSource.cpp	2015-12-22 21:58:27.655842760 +0100
@@ -248,7 +248,7 @@
     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#buffer-monitoring
 
     // Note, the behavior if activeSourceBuffers is empty is undefined.
-    if (!m_activeSourceBuffers) {
+    if (!m_activeSourceBuffers || m_activeSourceBuffers->length() == 0) {
         m_private->setReadyState(MediaPlayer::HaveNothing);
         return;
     }
diff -urN a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp	2015-12-22 21:58:27.655842760 +0100
@@ -762,6 +762,8 @@
         DecodeOrderSampleMap::MapType erasedSamples(removeDecodeStart, removeDecodeEnd);
         RefPtr<TimeRanges> erasedRanges = removeSamplesFromTrackBuffer(erasedSamples, trackBuffer, this, "removeCodedFrames");
 
+        // GStreamer backend doesn't support re-enqueue without preceding flushing seek, so just avoid adding same data to pipeline
+#if !USE(GSTREAMER)
         // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
         // not yet displayed samples.
         if (trackBuffer.lastEnqueuedPresentationTime.isValid() && currentMediaTime < trackBuffer.lastEnqueuedPresentationTime) {
@@ -770,6 +772,7 @@
             if (possiblyEnqueuedRanges.length())
                 trackBuffer.needsReenqueueing = true;
         }
+#endif
 
         erasedRanges->invert();
         trackBuffer.m_buffered->intersectWith(*erasedRanges);
@@ -1559,6 +1562,8 @@
 
             RefPtr<TimeRanges> erasedRanges = removeSamplesFromTrackBuffer(dependentSamples, trackBuffer, this, "sourceBufferPrivateDidReceiveSample");
 
+            // GStreamer backend doesn't support re-enqueue without preceding flushing seek, so just avoid adding same data to pipeline
+#if !USE(GSTREAMER)
             // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
             // not yet displayed samples.
             MediaTime currentMediaTime = m_source->currentTime();
@@ -1568,7 +1573,7 @@
                 if (possiblyEnqueuedRanges.length())
                     trackBuffer.needsReenqueueing = true;
             }
-
+#endif
             erasedRanges->invert();
             trackBuffer.m_buffered->intersectWith(*erasedRanges);
         }
diff -urN a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h	2015-12-22 21:58:27.659842760 +0100
@@ -94,7 +94,7 @@
 
     float duration() const override;
     float currentTime() const override;
-    void seek(float) override;
+    virtual void seek(float) override;
 
     void setRate(float) override;
     double rate() const override;
@@ -123,7 +123,7 @@
 
     void simulateAudioInterruption() override;
 
-    bool changePipelineState(GstState);
+    virtual bool changePipelineState(GstState);
 
 #if ENABLE(WEB_AUDIO)
     AudioSourceProvider* audioSourceProvider() override { return reinterpret_cast<AudioSourceProvider*>(m_audioSourceProvider.get()); }
@@ -146,7 +146,7 @@
     float playbackPosition() const;
 
     virtual void updateStates();
-    void asyncStateChangeDone();
+    virtual void asyncStateChangeDone();
 
     void createGSTPlayBin();
 
diff -urN a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerMSE.cpp b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerMSE.cpp
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerMSE.cpp	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerMSE.cpp	2015-12-22 22:00:05.139838624 +0100
@@ -213,7 +213,8 @@
 
 MediaPlayerPrivateGStreamerMSE::MediaPlayerPrivateGStreamerMSE(MediaPlayer* player)
     : MediaPlayerPrivateGStreamer(player)
-    , m_seekCompleted(true)
+    , m_mseSeekCompleted(true)
+    , m_gstSeekCompleted(true)
 {
     LOG_MEDIA_MESSAGE("%p", this);
 }
@@ -271,16 +272,167 @@
     return m_mediaTimeDuration.toFloat();
 }
 
+float MediaPlayerPrivateGStreamerMSE::mediaTimeForTimeValue(float timeValue) const
+{
+    GstClockTime position = toGstClockTime(timeValue);
+    return MediaTime(position, GST_SECOND).toFloat();
+}
+
+void MediaPlayerPrivateGStreamerMSE::seek(float time)
+{
+    if (!m_pipeline)
+        return;
+
+    if (m_errorOccured)
+        return;
+
+    INFO_MEDIA_MESSAGE("[Seek] seek attempt to %f secs", time);
+
+    // Avoid useless seeking.
+    float current = currentTime();
+    if (time == current) {
+        if (!m_seeking)
+            timeChanged();
+        return;
+    }
+
+    if (isLiveStream())
+        return;
+
+    if (m_seeking && m_seekIsPending) {
+        m_seekTime = time;
+        return;
+    }
+
+    LOG_MEDIA_MESSAGE("Seeking from %f to %f seconds", current, time);
+
+    float prevSeekTime = m_seekTime;
+    m_seekTime = time;
+
+    if (!doSeek()) {
+        m_seekTime = prevSeekTime;
+        LOG_MEDIA_MESSAGE("Seeking to %f failed", time);
+        return;
+    }
+
+    m_isEndReached = false;
+    LOG_MEDIA_MESSAGE("m_seeking=%s, m_seekTime=%f", m_seeking?"true":"false", m_seekTime);
+}
+
+bool MediaPlayerPrivateGStreamerMSE::changePipelineState(GstState newState)
+{
+    if (seeking()) {
+        LOG_MEDIA_MESSAGE("Rejected state change to %s while seeking",
+            gst_element_state_get_name(newState));
+        return true;
+    }
+
+    return MediaPlayerPrivateGStreamer::changePipelineState(newState);
+}
+
 void MediaPlayerPrivateGStreamerMSE::notifySeekNeedsData(const MediaTime& seekTime)
 {
     // Reenqueue samples needed to resume playback in the new position
     m_mediaSource->seekToTime(seekTime);
 
     LOG_MEDIA_MESSAGE("MSE seek to %f finished", seekTime.toDouble());
+
+    if (!m_gstSeekCompleted) {
+        m_gstSeekCompleted = true;
+        maybeFinishSeek();
+    }
+}
+
+bool MediaPlayerPrivateGStreamerMSE::doSeek(gint64, float, GstSeekFlags)
+{
+    // Use doSeek() instead. If anybody is calling this version of doSeek(), something is wrong.
+    notImplemented();
+    ASSERT_NOT_REACHED();
+    return false;
 }
 
-bool MediaPlayerPrivateGStreamerMSE::doSeek(gint64 position, float rate, GstSeekFlags seekType)
+bool MediaPlayerPrivateGStreamerMSE::doSeek()
 {
+    GstClockTime position = toGstClockTime(m_seekTime);
+    MediaTime seekTime = MediaTime::createWithDouble(m_seekTime + MediaTime::FuzzinessThreshold);
+    double rate = m_player->rate();
+    GstSeekFlags seekType = static_cast<GstSeekFlags>(GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_ACCURATE);
+
+    // Always move to seeking state to report correct 'currentTime' while pending for actual seek to complete
+    m_seeking = true;
+
+    // Check if playback pipeline is ready for seek
+    GstState state;
+    GstState newState;
+    GstStateChangeReturn getStateResult = gst_element_get_state(m_pipeline.get(), &state, &newState, 0);
+    if (getStateResult == GST_STATE_CHANGE_FAILURE || getStateResult == GST_STATE_CHANGE_NO_PREROLL) {
+        LOG_MEDIA_MESSAGE("[Seek] cannot seek, current state change is %s",
+                          gst_element_state_change_return_get_name(getStateResult));
+        webkit_media_src_set_readyforsamples(WEBKIT_MEDIA_SRC(m_source.get()), true);
+        m_seeking = false;
+        return false;
+    }
+    if (getStateResult == GST_STATE_CHANGE_ASYNC
+            || state < GST_STATE_PAUSED
+            || m_isEndReached
+            || !m_gstSeekCompleted) {
+        CString reason = "Unknown reason";
+        if (getStateResult == GST_STATE_CHANGE_ASYNC)
+            reason = String::format("In async change %s --> %s",
+                                    gst_element_state_get_name(state),
+                                    gst_element_state_get_name(newState)).utf8();
+        else if (state < GST_STATE_PAUSED)
+            reason = "State less than PAUSED";
+        else if (m_isEndReached)
+            reason = "End reached";
+        else if (!m_gstSeekCompleted)
+            reason = "Previous seek is not finished yet";
+
+        LOG_MEDIA_MESSAGE("[Seek] Delaying the seek: %s", reason.data());
+
+        m_seekIsPending = true;
+
+        if (m_isEndReached) {
+            LOG_MEDIA_MESSAGE("[Seek] reset pipeline");
+            m_resetPipeline = true;
+            m_seeking = false;
+            if (!changePipelineState(GST_STATE_PAUSED))
+                loadingFailed(MediaPlayer::Empty);
+            else
+                m_seeking = true;
+        }
+
+        return m_seeking;
+    }
+
+    // Stop accepting new samples until actual seek is finished
+    webkit_media_src_set_readyforsamples(WEBKIT_MEDIA_SRC(m_source.get()), false);
+
+    // Check if MSE has samples for requested time and defer actual seek if needed
+    if (!timeIsBuffered(seekTime)) {
+        LOG_MEDIA_MESSAGE("[Seek] Delaying the seek: MSE is not ready");
+        GstStateChangeReturn setStateResult = gst_element_set_state(m_pipeline.get(), GST_STATE_PAUSED);
+        if (setStateResult == GST_STATE_CHANGE_FAILURE) {
+            LOG_MEDIA_MESSAGE("[Seek] Cannot seek, failed to pause playback pipeline.");
+            webkit_media_src_set_readyforsamples(WEBKIT_MEDIA_SRC(m_source.get()), true);
+            m_seeking = false;
+            return false;
+        }
+        m_readyState = MediaPlayer::HaveMetadata;
+        notifySeekNeedsData(seekTime);
+        ASSERT(!m_mseSeekCompleted);
+        return true;
+    }
+
+    // Complete previous MSE seek if needed
+    if (!m_mseSeekCompleted) {
+        m_mediaSource->monitorSourceBuffers();
+        ASSERT(m_mseSeekCompleted);
+        return m_seeking;  // Note seekCompleted will recursively call us
+    }
+
+    LOG_MEDIA_MESSAGE("We can seek now");
+
     gint64 startTime, endTime;
 
     if (rate > 0) {
@@ -288,12 +440,7 @@
         endTime = GST_CLOCK_TIME_NONE;
     } else {
         startTime = 0;
-        // If we are at beginning of media, start from the end to
-        // avoid immediate EOS.
-        if (position < 0)
-            endTime = static_cast<gint64>(duration() * GST_SECOND);
-        else
-            endTime = position;
+        endTime = position;
     }
 
     if (!rate)
@@ -301,13 +448,15 @@
 
     LOG_MEDIA_MESSAGE("Actual seek to %" GST_TIME_FORMAT ", end time:  %" GST_TIME_FORMAT ", rate: %f", GST_TIME_ARGS(startTime), GST_TIME_ARGS(endTime), rate);
 
-    MediaTime time(MediaTime::createWithDouble(double(static_cast<double>(position) / GST_SECOND)));
-
     // This will call notifySeekNeedsData() after some time to tell that the pipeline is ready for sample enqueuing.
-    webkit_media_src_prepare_seek(WEBKIT_MEDIA_SRC(m_source.get()), time);
+    webkit_media_src_prepare_seek(WEBKIT_MEDIA_SRC(m_source.get()), seekTime);
 
+    m_gstSeekCompleted = false;
     if (!gst_element_seek(m_pipeline.get(), rate, GST_FORMAT_TIME, seekType,
         GST_SEEK_TYPE_SET, startTime, GST_SEEK_TYPE_SET, endTime)) {
+        webkit_media_src_set_readyforsamples(WEBKIT_MEDIA_SRC(m_source.get()), true);
+        m_seeking = false;
+        m_gstSeekCompleted = true;
         LOG_MEDIA_MESSAGE("Returning false");
         return false;
     }
@@ -317,6 +466,39 @@
     return true;
 }
 
+void MediaPlayerPrivateGStreamerMSE::maybeFinishSeek()
+{
+    if (!m_seeking || !m_mseSeekCompleted || !m_gstSeekCompleted) {
+        return;
+    }
+
+    GstStateChangeReturn getStateResult = gst_element_get_state(m_pipeline.get(), NULL, NULL, 0);
+    if (getStateResult == GST_STATE_CHANGE_ASYNC) {
+        LOG_MEDIA_MESSAGE("[Seek] Delaying seek finish");
+        return;
+    }
+
+    if (m_seekIsPending) {
+        LOG_MEDIA_MESSAGE("[Seek] Committing pending seek to %f", m_seekTime);
+        m_seekIsPending = false;
+        if (!doSeek()) {
+            LOG_MEDIA_MESSAGE("[Seek] Seeking to %f failed", m_seekTime);
+            m_cachedPosition = -1;
+        }
+        return;
+    }
+
+    LOG_MEDIA_MESSAGE("[Seek] Seeked to %f", m_seekTime);
+
+    webkit_media_src_set_readyforsamples(WEBKIT_MEDIA_SRC(m_source.get()), true);
+    m_seeking = false;
+    m_cachedPosition = -1;
+    // The pipeline can still have a pending state. In this case a position query will fail.
+    // Right now we can use m_seekTime as a fallback.
+    m_canFallBackToLastFinishedSeekPosition = true;
+    timeChanged();
+}
+
 void MediaPlayerPrivateGStreamerMSE::updatePlaybackRate()
 {
     notImplemented();
@@ -324,7 +506,7 @@
 
 bool MediaPlayerPrivateGStreamerMSE::seeking() const
 {
-    return m_seeking && !m_seekCompleted;
+    return m_seeking;
 }
 
 // METRO FIXME: GStreamer mediaplayer manages the readystate on its own. We shouldn't change it manually.
@@ -332,6 +514,11 @@
 {
     // FIXME: early return here.
     if (state != m_readyState) {
+        if (seeking()) {
+            LOG_MEDIA_MESSAGE("Skip ready state change(%s -> %s) due to seek\n", dumpReadyState(m_readyState), dumpReadyState(state));
+            return;
+        }
+
         LOG_MEDIA_MESSAGE("Ready State Changed manually from %u to %u", m_readyState, state);
         MediaPlayer::ReadyState oldReadyState = m_readyState;
         m_readyState = state;
@@ -343,8 +530,7 @@
 
         if (m_readyState == MediaPlayer::HaveMetadata && oldReadyState > MediaPlayer::HaveMetadata && isPlaying) {
             LOG_MEDIA_MESSAGE("Changing pipeline to PAUSED...");
-            // Not using changePipelineState() because we don't want the state to drop to GST_STATE_NULL ever.
-            bool ok = gst_element_set_state(m_pipeline.get(), GST_STATE_PAUSED) == GST_STATE_CHANGE_SUCCESS;
+            bool ok = changePipelineState(GST_STATE_PAUSED);
             LOG_MEDIA_MESSAGE("Changing pipeline to PAUSED: %s", (ok)?"OK":"ERROR");
         }
         if (oldReadyState < MediaPlayer::HaveCurrentData && m_readyState >= MediaPlayer::HaveCurrentData) {
@@ -361,21 +547,23 @@
         return;
 
     LOG_MEDIA_MESSAGE("Waiting for MSE seek completed");
-    m_seekCompleted = false;
+    m_mseSeekCompleted = false;
 }
 
 void MediaPlayerPrivateGStreamerMSE::seekCompleted()
 {
-    if (m_seekCompleted)
+    if (m_mseSeekCompleted)
         return;
 
     LOG_MEDIA_MESSAGE("MSE seek completed");
-    m_seekCompleted = true;
+    m_mseSeekCompleted = true;
+
+    doSeek();
 
     if (!seeking() && m_readyState >= MediaPlayer::HaveFutureData)
-        gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
+        changePipelineState(GST_STATE_PLAYING);
 
-    if (!m_seeking)
+    if (!seeking())
         m_player->timeChanged();
 }
 
@@ -455,7 +643,7 @@
             break;
         case GST_STATE_PAUSED:
         case GST_STATE_PLAYING:
-            if (m_seeking && !timeIsBuffered(m_seekTime)) {
+            if (seeking()) {
                 m_readyState = MediaPlayer::HaveMetadata;
                 // TODO: NetworkState?
                 LOG_MEDIA_MESSAGE("m_readyState=%s", dumpReadyState(m_readyState));
@@ -566,23 +754,24 @@
 
     if (getStateResult == GST_STATE_CHANGE_SUCCESS && state >= GST_STATE_PAUSED) {
         updatePlaybackRate();
-        if (m_seekIsPending && timeIsBuffered(m_seekTime)) {
-            LOG_MEDIA_MESSAGE("[Seek] committing pending seek to %f", m_seekTime);
-            m_seekIsPending = false;
-            m_seeking = doSeek(toGstClockTime(m_seekTime), m_player->rate(), static_cast<GstSeekFlags>(GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_ACCURATE));
-            LOG_MEDIA_MESSAGE("m_seeking=%s", m_seeking?"true":"false");
-            if (!m_seeking) {
-                m_cachedPosition = -1;
-                LOG_MEDIA_MESSAGE("[Seek] seeking to %f failed", m_seekTime);
-            }
-        }
+        maybeFinishSeek();
     }
 }
+void MediaPlayerPrivateGStreamerMSE::asyncStateChangeDone()
+{
+    if (!m_pipeline || m_errorOccured)
+        return;
+
+    if (m_seeking)
+        maybeFinishSeek();
+    else
+        updateStates();
+}
 
-bool MediaPlayerPrivateGStreamerMSE::timeIsBuffered(float time)
+bool MediaPlayerPrivateGStreamerMSE::timeIsBuffered(const MediaTime &time) const
 {
-    bool result = m_mediaSource && m_mediaSource->buffered()->contain(MediaTime::createWithFloat(time));
-    LOG_MEDIA_MESSAGE("Time %f buffered? %s", time, result ? "aye" : "nope");
+    bool result = m_mediaSource && m_mediaSource->buffered()->contain(time);
+    LOG_MEDIA_MESSAGE("Time %f buffered? %s", time.toDouble(), result ? "aye" : "nope");
     return result;
 }
 
diff -urN a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerMSE.h b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerMSE.h
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerMSE.h	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerMSE.h	2015-12-22 21:58:40.039842235 +0100
@@ -55,9 +55,13 @@
     bool isLiveStream() const override { return false; }
 
     bool seeking() const override;
+    void seek(float) override;
+    bool changePipelineState(GstState) override;
+
     void durationChanged() override;
     MediaTime durationMediaTime() const override { return m_mediaTimeDuration; }
     float duration() const override;
+    float mediaTimeForTimeValue(float timeValue) const;
     void setRate(float) override;
     std::unique_ptr<PlatformTimeRanges> buffered() const override;
 
@@ -88,14 +92,18 @@
     void updateStates() override;
 
     bool doSeek(gint64 position, float rate, GstSeekFlags seekType) override;
+    bool doSeek();
+    void maybeFinishSeek();
     void updatePlaybackRate() override;
+    void asyncStateChangeDone() override;
+
 
     // TODO: Implement
     unsigned long totalVideoFrames() override { return 0; }
     unsigned long droppedVideoFrames() override { return 0; }
     unsigned long corruptedVideoFrames() override { return 0; }
     MediaTime totalFrameDelay() override { return MediaTime::zeroTime(); }
-    bool timeIsBuffered(float);
+    bool timeIsBuffered(const MediaTime &time) const;
 
     bool isMediaSource() const override { return true; }
 
@@ -105,7 +113,8 @@
     RefPtr<AppendPipeline> appendPipelineByTrackId(const AtomicString& trackId);
 
     RefPtr<MediaSourcePrivateClient> m_mediaSource;
-    bool m_seekCompleted;
+    bool m_mseSeekCompleted;
+    bool m_gstSeekCompleted;
 
     HashMap<RefPtr<SourceBufferPrivateGStreamer>, RefPtr<AppendPipeline> > m_appendPipelinesMap;
     RefPtr<PlaybackPipeline> m_playbackPipeline;
diff -urN a/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp
--- a/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp	2015-12-22 21:58:27.659842760 +0100
@@ -55,6 +55,7 @@
     , m_mediaSource(mediaSource)
     , m_type(contentType)
     , m_client(client)
+    , m_isReadyForMoreSamples(true)
 {
 }
 
@@ -117,7 +118,12 @@
 
 bool SourceBufferPrivateGStreamer::isReadyForMoreSamples(AtomicString)
 {
-    return true;
+    return m_isReadyForMoreSamples;
+}
+
+void SourceBufferPrivateGStreamer::setReadyForMoreSamples(bool isReady)
+{
+    m_isReadyForMoreSamples = isReady;
 }
 
 void SourceBufferPrivateGStreamer::setActive(bool isActive)
diff -urN a/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h
--- a/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h	2015-12-22 21:58:27.659842760 +0100
@@ -68,6 +68,8 @@
     virtual void notifyClientWhenReadyForMoreSamples(AtomicString) override;
     virtual double timestampOffset() const;
 
+    void setReadyForMoreSamples(bool isReady);
+
 #if ENABLE(VIDEO_TRACK)
     void didReceiveInitializationSegment(const SourceBufferPrivateClient::InitializationSegment&);
     void didReceiveSample(PassRefPtr<MediaSample>);
@@ -82,6 +84,7 @@
     ContentType m_type;
     RefPtr<MediaSourceClientGStreamerMSE> m_client;
     SourceBufferPrivateClient* m_sourceBufferPrivateClient;
+    bool m_isReadyForMoreSamples;
 };
 
 }
diff -urN a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
--- a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp	2015-12-22 21:58:27.659842760 +0100
@@ -680,6 +680,15 @@
     MediaTime seekTime = webKitMediaSrc->priv->seekTime;
     WebCore::MediaPlayerPrivateGStreamerMSE* mediaPlayerPrivate = webKitMediaSrc->priv->mediaPlayerPrivate;
     GST_OBJECT_UNLOCK(webKitMediaSrc);
+
+
+    for (GList* streams = webKitMediaSrc->priv->streams; streams; streams = streams->next) {
+        Stream* stream = static_cast<Stream*>(streams->data);
+        if (stream->type != WebCore::Invalid) {
+            stream->sourceBuffer->setReadyForMoreSamples(true);
+        }
+    }
+
     mediaPlayerPrivate->notifySeekNeedsData(seekTime);
 
     return G_SOURCE_REMOVE;
@@ -1179,13 +1188,21 @@
         return;
     }
 
+    if (!stream->sourceBuffer->isReadyForMoreSamples(trackId)) {
+        LOG_MEDIA_MESSAGE("flushAndEnqueueNonDisplayingSamples: skip adding new sample for trackId=%s, SB is not ready yet", trackId.string().utf8().data());
+        GST_OBJECT_UNLOCK(m_webKitMediaSrc.get());
+        return;
+    }
+
     GstElement* appsrc = stream->appsrc;
     MediaTime lastEnqueuedTime = stream->lastEnqueuedTime;
     GST_OBJECT_UNLOCK(m_webKitMediaSrc.get());
 
     double timestampOffset = stream->sourceBuffer->timestampOffset();
 
-    // Actually no need to flush. The seek preparations have done it for us.
+    if (!m_webKitMediaSrc->priv->mediaPlayerPrivate->seeking()) {
+        LOG_MEDIA_MESSAGE("flushAndEnqueueNonDisplayingSamples: trackId=%s pipeline needs flushing.", trackId.string().utf8().data());
+    }
 
     for (Vector<RefPtr<MediaSample> >::iterator it = samples.begin(); it != samples.end(); ++it) {
         GStreamerMediaSample* sample = static_cast<GStreamerMediaSample*>(it->get());
@@ -1227,6 +1244,12 @@
         return;
     }
 
+    if (!stream->sourceBuffer->isReadyForMoreSamples(trackId)) {
+        LOG_MEDIA_MESSAGE("enqueueSample: skip adding new sample for trackId=%s, SB is not ready yet", trackId.string().utf8().data());
+        GST_OBJECT_UNLOCK(m_webKitMediaSrc.get());
+        return;
+    }
+
     GstElement* appsrc = stream->appsrc;
     MediaTime lastEnqueuedTime = stream->lastEnqueuedTime;
     GST_OBJECT_UNLOCK(m_webKitMediaSrc.get());
@@ -1269,6 +1292,18 @@
     GST_OBJECT_UNLOCK(src);
 }
 
+void webkit_media_src_set_readyforsamples(WebKitMediaSrc* src, bool isReady)
+{
+    if (src) {
+        GST_OBJECT_LOCK(src);
+        for (GList* streams = src->priv->streams; streams; streams = streams->next) {
+            Stream* stream = static_cast<Stream*>(streams->data);
+            stream->sourceBuffer->setReadyForMoreSamples(isReady);
+        }
+        GST_OBJECT_UNLOCK(src);
+    }
+}
+
 void webkit_media_src_prepare_seek(WebKitMediaSrc* src, const MediaTime& time)
 {
     GST_OBJECT_LOCK(src);
diff -urN a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h
--- a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h	2015-12-22 21:58:27.659842760 +0100
@@ -72,6 +72,7 @@
 void webkit_media_src_set_mediaplayerprivate(WebKitMediaSrc* src, WebCore::MediaPlayerPrivateGStreamerMSE* player);
 
 void webkit_media_src_prepare_seek(WebKitMediaSrc*, const MediaTime&);
+void webkit_media_src_set_readyforsamples(WebKitMediaSrc*, bool);
 
 G_END_DECLS
 
diff -urN a/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h b/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h
--- a/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h	2015-12-20 12:13:42.000000000 +0100
+++ b/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h	2015-12-22 21:58:27.659842760 +0100
@@ -44,6 +44,7 @@
     virtual void durationChanged(const MediaTime&) = 0;
     virtual std::unique_ptr<PlatformTimeRanges> buffered() const = 0;
     virtual void seekToTime(const MediaTime&) = 0;
+    virtual void monitorSourceBuffers() = 0;
 };
 
 }
